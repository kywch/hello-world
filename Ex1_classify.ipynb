{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import codecs\n",
    "import csv\n",
    "import os\n",
    "from sklearn import metrics\n",
    "\n",
    "path = 'D:\\Dropbox\\ongoing\\chrisIntervention'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of cohort 1:  148\n",
      "# of cohort 2:  197\n"
     ]
    }
   ],
   "source": [
    "# read cohort info from the CSV and save them with the sbj ID\n",
    "\n",
    "intvIdx = 'Ex1'\n",
    "\n",
    "category = {}\n",
    "with open(os.path.join(path, intvIdx + '_key.csv')) as f:\n",
    "    sbjData = csv.reader(f)\n",
    "    next(sbjData) # skip the header\n",
    "    for row in sbjData:\n",
    "        category[row[0]] = int(row[1])\n",
    "\n",
    "subjectId = category.keys()        \n",
    "        \n",
    "#print(subjectId)\n",
    "#print()\n",
    "print('# of cohort 1: ', sum(1 for sbj in category if category[sbj] == 1))\n",
    "print('# of cohort 2: ', sum(1 for sbj in category if category[sbj] == 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['football', 'has', 'more', 'own', 'matter', 'listing', 'two', 'than', 'friends', 'still', 'was', 'bad', 'well', 'favorite', 'out', 'say', 'fun', 'old', 'help', 'sister', 'different', 'hang', 'mind', 'homework', 'much', 'really', 'rap', 'when', 'mad', 'from', 'sence', 'most', 'free', 'times', 'everyday', 'why', 'want', 'art', 'down', 'makes', 'after', 'and', 'learn', 'can', 'value', 'had', 'games', 'gives', 'back', 'team', 'ever', 'new', 'whole', 'just', 'its', 'happy', 'keep', 'stuff', 'let', 'years', 'hard', 'day', 'people', 'others', 'spending', 'friend', 'chose', 'not', 'love', 'anything', 'them', 'because', 'your', 'alone', 'soccer', 'enjoy', 'someone', 'listening', 'have', 'calm', 'then', 'also', 'their', 'sport', 'try', 'the', 'stay', 'done', 'without', 'lots', 'close', 'away', 'last', 'great', 'parents', 'helps', 'these', 'thing', 'things', 'brother', 'living', 'into', 'very', 'home', 'little', 'for', 'other', 'happen', 'feeling', 'sad', 'songs', 'smile', 'nice', 'way', 'trouble', 'enjoying', 'second', 'think', 'another', 'sports', 'cheer', 'yourself', 'what', 'cause', 'need', 'today', 'about', 'important', 'see', 'picked', 'part', 'funny', 'alway', 'this', 'freinds', 'calms', 'going', 'some', 'god', 'don', 'values', 'group', 'only', 'were', 'writing', 'they', 'jokes', 'take', 'feel', 'kind', 'should', 'hear', 'music', 'with', 'something', 'around', 'humor', 'are', 'many', 'inportant', 'how', 'hop', 'thats', 'look', 'play', 'lot', 'hip', 'keeps', 'all', 'time', 'first', 'listen', 'dance', 'once', 'always', 'care', 'got', 'making', 'draw', 'life', 'through', 'tell', 'reason', 'those', 'independent', 'able', 'any', 'together', 'active', 'could', 'such', 'dont', 'having', 'but', 'who', 'trust', 'wouldn', 'hanging', 'mean', 'long', 'basketball', 'been', 'playing', 'everyone', 'work', 'alot', 'else', 'will', 'get', 'game', 'like', 'sense', 'started', 'healthy', 'world', 'doing', 'every', 'never', 'live', 'talk', 'now', 'you', 'better', 'comes', 'sometimes', 'put', 'grade', 'social', 'where', 'religious', 'even', 'she', 'show', 'boring', 'there', 'that', 'make', 'school', 'creativity', 'myself', 'bored', 'everything', 'best', 'side', 'drawing', 'moment', 'know', 'made', 'big', 'creative', 'dad', 'angry', 'one', 'same', 'family', 'express', 'being', 'nothing', 'good', 'spend', 'mom', 'would', 'while', 'laugh', 'sing', 'ball']\n"
     ]
    }
   ],
   "source": [
    "# build the dictionary based on the training set\n",
    "# this is just to check if it is working\n",
    "# we should build the dictionary for each leave-one-out test\n",
    "\n",
    "def make_dictionary(subjectPool, critNumSbj):\n",
    "    allWords = []\n",
    "    for sbj in subjectPool:\n",
    "        sbjWords = []\n",
    "        for line in codecs.open(os.path.join(path, intvIdx, sbj + '.txt'), 'r' , 'utf-8'):\n",
    "            line = line.strip()\n",
    "            line = line.lower()\n",
    "            tokens = nltk.wordpunct_tokenize(line)\n",
    "            text = nltk.Text(tokens)\n",
    "            words = [w for w in text if re.search('[a-z]+',w) and len(w)>2]\n",
    "            sbjWords.extend(words)\n",
    "        # when making dictionary, make the words from a document unique\n",
    "        sbjWords = list(set(sbjWords))\n",
    "        allWords.extend(sbjWords)\n",
    "    \n",
    "    # once we make list of all words, we count the words\n",
    "    cntWords = nltk.FreqDist(allWords)\n",
    "    #for ii in range(21,0,-2):\n",
    "    #    print('# words with freq >', ii, ' : ', sum(1 for word in cntWords if cntWords[word] > ii))\n",
    "    \n",
    "    # we go with the words that came from at least N different people (arbitrary) \n",
    "    # we can change and see what happens ...\n",
    "    return [word for word in cntWords if cntWords[word] > critNumSbj]\n",
    "\n",
    "dictionary = make_dictionary(subjectId, 5)\n",
    "\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nltk output:  ['You', 'think', 'you', 'can', 'do', 'this', 'one', ',', 'Kate', '?']\n",
      "{'today': False, 'about': False, 'different': False, 'into': False, 'important': False, 'anything': False, 'creativity': False, 'them': False, 'boring': False, 'are': False, 'wouldn': False, 'many': False, 'enjoying': False, 'football': False, 'only': False, 'very': False, 'home': False, 'most': False, 'friend': False, 'hop': False, 'chose': False, 'school': False, 'that': False, 'thats': False, 'look': False, 'picked': False, 'part': False, 'your': False, 'being': False, 'play': False, 'lot': False, 'funny': False, 'hip': False, 'everyday': False, 'keeps': False, 'everything': False, 'all': False, 'this': True, 'make': False, 'more': False, 'inportant': False, 'see': False, 'where': False, 'time': False, 'long': False, 'basketball': False, 'nothing': False, 'why': False, 'alone': False, 'for': False, 'been': False, 'playing': False, 'world': False, 'everyone': False, 'other': False, 'happen': False, 'art': False, 'making': False, 'around': False, 'own': False, 'first': False, 'parents': False, 'calms': False, 'soccer': False, 'enjoy': False, 'matter': False, 'going': False, 'values': False, 'listening': False, 'have': False, 'down': False, 'god': False, 'let': False, 'calm': False, 'don': False, 'cheer': False, 'their': False, 'want': False, 'than': False, 'sad': False, 'cause': False, 'when': False, 'friends': False, 'mean': False, 'get': False, 'not': False, 'freinds': False, 'game': False, 'was': False, 'like': False, 'having': False, 'group': False, 'because': False, 'she': False, 'songs': False, 'smile': False, 'after': False, 'spend': False, 'then': False, 'once': False, 'and': False, 'still': False, 'also': False, 'learn': False, 'nice': False, 'who': False, 'sport': False, 'best': False, 'try': False, 'while': False, 'can': True, 'feeling': False, 'the': False, 'always': False, 'able': False, 'stay': False, 'fun': False, 'care': False, 'had': False, 'side': False, 'without': False, 'gives': False, 'lots': False, 'well': False, 'how': False, 'trouble': False, 'were': False, 'favorite': False, 'know': False, 'draw': False, 'much': False, 'big': False, 'would': False, 'life': False, 'made': False, 'express': False, 'creative': False, 'team': False, 'religious': False, 'there': False, 'alot': False, 'free': False, 'through': False, 'second': False, 'ever': False, 'doing': False, 'think': True, 'new': False, 'they': False, 'tell': False, 'every': False, 'whole': False, 'value': False, 'reason': False, 'live': False, 'another': False, 'those': False, 'away': False, 'old': False, 'just': False, 'help': False, 'independent': False, 'someone': False, 'jokes': False, 'sence': False, 'talk': False, 'its': False, 'angry': False, 'sports': False, 'work': False, 'comes': False, 'great': False, 'happy': False, 'ball': False, 'now': False, 'something': False, 'good': False, 'games': False, 'kind': False, 'love': False, 'hang': False, 'mind': False, 'any': False, 'you': True, 'else': False, 'back': False, 'has': False, 'healthy': False, 'stuff': False, 'take': False, 'together': False, 'active': False, 'bad': False, 'years': False, 'put': False, 'could': False, 'family': False, 'two': False, 'out': False, 'say': False, 'day': False, 'grade': False, 'never': False, 'started': False, 'these': False, 'some': False, 'yourself': False, 'writing': False, 'sometimes': False, 'homework': False, 'helps': False, 'feel': False, 'got': False, 'moment': False, 'listen': False, 'such': False, 'should': False, 'what': False, 'hear': False, 'times': False, 'done': False, 'from': False, 'others': False, 'music': False, 'dance': False, 'spending': False, 'sister': False, 'hard': False, 'myself': False, 'thing': False, 'little': False, 'with': False, 'social': False, 'really': False, 'rap': False, 'dad': False, 'one': True, 'mom': False, 'need': False, 'better': False, 'same': False, 'makes': False, 'but': False, 'sing': False, 'listing': False, 'bored': False, 'way': False, 'sense': False, 'mad': False, 'even': False, 'drawing': False, 'close': False, 'keep': False, 'things': False, 'humor': False, 'people': False, 'brother': False, 'dont': False, 'alway': False, 'laugh': False, 'last': False, 'trust': False, 'show': False, 'living': False, 'will': False, 'hanging': False}\n"
     ]
    }
   ],
   "source": [
    "# we define a function that tunrs text into a list of tokens\n",
    "\n",
    "def extract_feature(text, dictionary):\n",
    "    text = text.strip()\n",
    "    text = text.lower()\n",
    "    tokens = nltk.wordpunct_tokenize(text)\n",
    "    text = nltk.Text(tokens)\n",
    "    feature = {}\n",
    "    for word in dictionary:\n",
    "        feature[word] = (word in text)\n",
    "    return feature\n",
    "\n",
    "print('nltk output: ', nltk.wordpunct_tokenize('You think you can do this one, Kate?'))\n",
    "print(extract_feature('You think you can do this one, Kate?', dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: pred - 1, actual - 1\n",
      "2: pred - 2, actual - 2\n",
      "3: pred - 1, actual - 2\n",
      "4: pred - 1, actual - 2\n",
      "5: pred - 1, actual - 1\n",
      "6: pred - 2, actual - 2\n",
      "7: pred - 2, actual - 1\n",
      "8: pred - 2, actual - 2\n",
      "9: pred - 2, actual - 1\n",
      "10: pred - 2, actual - 1\n",
      "11: pred - 2, actual - 2\n",
      "12: pred - 2, actual - 2\n",
      "13: pred - 1, actual - 1\n",
      "14: pred - 2, actual - 1\n",
      "15: pred - 2, actual - 2\n",
      "16: pred - 2, actual - 2\n",
      "17: pred - 2, actual - 2\n",
      "18: pred - 1, actual - 1\n",
      "19: pred - 2, actual - 2\n",
      "20: pred - 2, actual - 2\n",
      "21: pred - 2, actual - 1\n",
      "22: pred - 2, actual - 2\n",
      "23: pred - 1, actual - 1\n",
      "24: pred - 2, actual - 2\n",
      "25: pred - 1, actual - 1\n",
      "26: pred - 1, actual - 1\n",
      "27: pred - 2, actual - 2\n",
      "28: pred - 2, actual - 2\n",
      "29: pred - 2, actual - 2\n",
      "30: pred - 1, actual - 2\n",
      "31: pred - 2, actual - 2\n",
      "32: pred - 1, actual - 1\n",
      "33: pred - 2, actual - 1\n",
      "34: pred - 1, actual - 1\n",
      "35: pred - 2, actual - 2\n",
      "36: pred - 2, actual - 2\n",
      "37: pred - 1, actual - 2\n",
      "38: pred - 2, actual - 2\n",
      "39: pred - 2, actual - 2\n",
      "40: pred - 2, actual - 1\n",
      "41: pred - 1, actual - 2\n",
      "42: pred - 1, actual - 1\n",
      "43: pred - 2, actual - 1\n",
      "44: pred - 2, actual - 2\n",
      "45: pred - 2, actual - 2\n",
      "46: pred - 1, actual - 1\n",
      "47: pred - 1, actual - 1\n",
      "48: pred - 1, actual - 1\n",
      "49: pred - 1, actual - 2\n",
      "50: pred - 2, actual - 2\n",
      "51: pred - 2, actual - 2\n",
      "52: pred - 2, actual - 1\n",
      "53: pred - 1, actual - 2\n",
      "54: pred - 2, actual - 2\n",
      "55: pred - 2, actual - 2\n",
      "56: pred - 2, actual - 1\n",
      "57: pred - 2, actual - 2\n",
      "58: pred - 2, actual - 2\n",
      "59: pred - 2, actual - 2\n",
      "60: pred - 2, actual - 2\n",
      "61: pred - 2, actual - 2\n",
      "62: pred - 2, actual - 1\n",
      "63: pred - 2, actual - 2\n",
      "64: pred - 2, actual - 2\n",
      "65: pred - 2, actual - 2\n",
      "66: pred - 1, actual - 2\n",
      "67: pred - 2, actual - 1\n",
      "68: pred - 2, actual - 1\n",
      "69: pred - 1, actual - 1\n",
      "70: pred - 1, actual - 1\n",
      "71: pred - 2, actual - 2\n",
      "72: pred - 2, actual - 2\n",
      "73: pred - 1, actual - 1\n",
      "74: pred - 1, actual - 1\n",
      "75: pred - 1, actual - 1\n",
      "76: pred - 1, actual - 1\n",
      "77: pred - 2, actual - 1\n",
      "78: pred - 2, actual - 2\n",
      "79: pred - 2, actual - 1\n",
      "80: pred - 2, actual - 2\n",
      "81: pred - 1, actual - 1\n",
      "82: pred - 1, actual - 1\n",
      "83: pred - 2, actual - 1\n",
      "84: pred - 2, actual - 1\n",
      "85: pred - 2, actual - 2\n",
      "86: pred - 2, actual - 2\n",
      "87: pred - 2, actual - 2\n",
      "88: pred - 1, actual - 1\n",
      "89: pred - 2, actual - 2\n",
      "90: pred - 2, actual - 2\n",
      "91: pred - 1, actual - 1\n",
      "92: pred - 1, actual - 1\n",
      "93: pred - 2, actual - 2\n",
      "94: pred - 2, actual - 2\n",
      "95: pred - 2, actual - 2\n",
      "96: pred - 2, actual - 2\n",
      "97: pred - 2, actual - 2\n",
      "98: pred - 2, actual - 1\n",
      "99: pred - 2, actual - 2\n",
      "100: pred - 2, actual - 2\n",
      "101: pred - 2, actual - 2\n",
      "102: pred - 2, actual - 2\n",
      "103: pred - 1, actual - 1\n",
      "104: pred - 2, actual - 2\n",
      "105: pred - 2, actual - 2\n",
      "106: pred - 2, actual - 1\n",
      "107: pred - 2, actual - 2\n",
      "108: pred - 2, actual - 1\n",
      "109: pred - 1, actual - 1\n",
      "110: pred - 1, actual - 1\n",
      "111: pred - 1, actual - 1\n",
      "112: pred - 1, actual - 1\n",
      "113: pred - 1, actual - 1\n",
      "114: pred - 2, actual - 1\n",
      "115: pred - 2, actual - 2\n",
      "116: pred - 2, actual - 2\n",
      "117: pred - 1, actual - 1\n",
      "118: pred - 2, actual - 2\n",
      "119: pred - 1, actual - 1\n",
      "120: pred - 2, actual - 2\n",
      "121: pred - 1, actual - 1\n",
      "122: pred - 2, actual - 2\n",
      "123: pred - 2, actual - 2\n",
      "124: pred - 2, actual - 2\n",
      "125: pred - 2, actual - 1\n",
      "126: pred - 2, actual - 2\n",
      "127: pred - 2, actual - 2\n",
      "128: pred - 1, actual - 1\n",
      "129: pred - 2, actual - 2\n",
      "130: pred - 2, actual - 1\n",
      "131: pred - 1, actual - 2\n",
      "132: pred - 1, actual - 1\n",
      "133: pred - 2, actual - 2\n",
      "134: pred - 2, actual - 2\n",
      "135: pred - 2, actual - 1\n",
      "136: pred - 2, actual - 2\n",
      "137: pred - 2, actual - 2\n",
      "138: pred - 1, actual - 1\n",
      "139: pred - 2, actual - 1\n",
      "140: pred - 2, actual - 1\n",
      "141: pred - 2, actual - 2\n",
      "142: pred - 1, actual - 1\n",
      "143: pred - 2, actual - 1\n",
      "144: pred - 2, actual - 2\n",
      "145: pred - 2, actual - 2\n",
      "146: pred - 2, actual - 2\n",
      "147: pred - 2, actual - 1\n",
      "148: pred - 2, actual - 2\n",
      "149: pred - 2, actual - 1\n",
      "150: pred - 2, actual - 2\n",
      "151: pred - 2, actual - 2\n",
      "152: pred - 2, actual - 1\n",
      "153: pred - 2, actual - 2\n",
      "154: pred - 2, actual - 1\n",
      "155: pred - 1, actual - 1\n",
      "156: pred - 2, actual - 2\n",
      "157: pred - 2, actual - 2\n",
      "158: pred - 2, actual - 1\n",
      "159: pred - 2, actual - 2\n",
      "160: pred - 1, actual - 1\n",
      "161: pred - 1, actual - 1\n",
      "162: pred - 1, actual - 2\n",
      "163: pred - 2, actual - 2\n",
      "164: pred - 2, actual - 2\n",
      "165: pred - 1, actual - 1\n",
      "166: pred - 2, actual - 2\n",
      "167: pred - 2, actual - 2\n",
      "168: pred - 2, actual - 2\n",
      "169: pred - 2, actual - 2\n",
      "170: pred - 2, actual - 2\n",
      "171: pred - 2, actual - 2\n",
      "172: pred - 1, actual - 2\n",
      "173: pred - 1, actual - 2\n",
      "174: pred - 2, actual - 1\n",
      "175: pred - 1, actual - 2\n",
      "176: pred - 1, actual - 2\n",
      "177: pred - 2, actual - 2\n",
      "178: pred - 2, actual - 2\n",
      "179: pred - 2, actual - 1\n",
      "180: pred - 1, actual - 2\n",
      "181: pred - 2, actual - 2\n",
      "182: pred - 2, actual - 1\n",
      "183: pred - 2, actual - 2\n",
      "184: pred - 2, actual - 2\n",
      "185: pred - 2, actual - 2\n",
      "186: pred - 2, actual - 2\n",
      "187: pred - 2, actual - 2\n",
      "188: pred - 2, actual - 1\n",
      "189: pred - 1, actual - 2\n",
      "190: pred - 2, actual - 1\n",
      "191: pred - 2, actual - 2\n",
      "192: pred - 1, actual - 1\n",
      "193: pred - 2, actual - 2\n",
      "194: pred - 2, actual - 1\n",
      "195: pred - 2, actual - 1\n",
      "196: pred - 2, actual - 2\n",
      "197: pred - 2, actual - 2\n",
      "198: pred - 2, actual - 2\n",
      "199: pred - 2, actual - 2\n",
      "200: pred - 2, actual - 2\n",
      "201: pred - 2, actual - 2\n",
      "202: pred - 2, actual - 1\n",
      "203: pred - 2, actual - 2\n",
      "204: pred - 1, actual - 1\n",
      "205: pred - 1, actual - 1\n",
      "206: pred - 2, actual - 2\n",
      "207: pred - 2, actual - 2\n",
      "208: pred - 2, actual - 2\n",
      "209: pred - 1, actual - 1\n",
      "210: pred - 2, actual - 1\n",
      "211: pred - 1, actual - 1\n",
      "212: pred - 2, actual - 2\n",
      "213: pred - 1, actual - 1\n",
      "214: pred - 2, actual - 1\n",
      "215: pred - 2, actual - 2\n",
      "216: pred - 2, actual - 2\n",
      "217: pred - 1, actual - 1\n",
      "218: pred - 2, actual - 2\n",
      "219: pred - 2, actual - 2\n",
      "220: pred - 1, actual - 1\n",
      "221: pred - 2, actual - 2\n",
      "222: pred - 2, actual - 2\n",
      "223: pred - 2, actual - 2\n",
      "224: pred - 2, actual - 1\n",
      "225: pred - 1, actual - 1\n",
      "226: pred - 1, actual - 1\n",
      "227: pred - 2, actual - 2\n",
      "228: pred - 1, actual - 1\n",
      "229: pred - 1, actual - 1\n",
      "230: pred - 2, actual - 2\n",
      "231: pred - 1, actual - 2\n",
      "232: pred - 2, actual - 2\n",
      "233: pred - 1, actual - 2\n",
      "234: pred - 2, actual - 2\n",
      "235: pred - 2, actual - 2\n",
      "236: pred - 2, actual - 2\n",
      "237: pred - 2, actual - 2\n",
      "238: pred - 2, actual - 1\n",
      "239: pred - 1, actual - 1\n",
      "240: pred - 2, actual - 2\n",
      "241: pred - 2, actual - 1\n",
      "242: pred - 2, actual - 1\n",
      "243: pred - 2, actual - 2\n",
      "244: pred - 1, actual - 2\n",
      "245: pred - 2, actual - 2\n",
      "246: pred - 2, actual - 1\n",
      "247: pred - 2, actual - 2\n",
      "248: pred - 1, actual - 1\n",
      "249: pred - 1, actual - 1\n",
      "250: pred - 2, actual - 1\n",
      "251: pred - 1, actual - 2\n",
      "252: pred - 1, actual - 1\n",
      "253: pred - 2, actual - 2\n",
      "254: pred - 2, actual - 2\n",
      "255: pred - 2, actual - 2\n",
      "256: pred - 2, actual - 2\n",
      "257: pred - 2, actual - 2\n",
      "258: pred - 2, actual - 1\n",
      "259: pred - 2, actual - 2\n",
      "260: pred - 2, actual - 1\n",
      "261: pred - 1, actual - 2\n",
      "262: pred - 2, actual - 2\n",
      "263: pred - 2, actual - 2\n",
      "264: pred - 1, actual - 1\n",
      "265: pred - 1, actual - 1\n",
      "266: pred - 2, actual - 1\n",
      "267: pred - 1, actual - 1\n",
      "268: pred - 1, actual - 1\n",
      "269: pred - 2, actual - 2\n",
      "270: pred - 2, actual - 1\n",
      "271: pred - 2, actual - 2\n",
      "272: pred - 2, actual - 2\n",
      "273: pred - 2, actual - 2\n",
      "274: pred - 1, actual - 1\n",
      "275: pred - 1, actual - 2\n",
      "276: pred - 2, actual - 2\n",
      "277: pred - 1, actual - 2\n",
      "278: pred - 1, actual - 1\n",
      "279: pred - 2, actual - 2\n",
      "280: pred - 1, actual - 1\n",
      "281: pred - 2, actual - 2\n",
      "282: pred - 2, actual - 2\n",
      "283: pred - 2, actual - 2\n",
      "284: pred - 1, actual - 1\n",
      "285: pred - 1, actual - 2\n",
      "286: pred - 2, actual - 1\n",
      "287: pred - 1, actual - 2\n",
      "288: pred - 2, actual - 1\n",
      "289: pred - 1, actual - 1\n",
      "290: pred - 2, actual - 2\n",
      "291: pred - 1, actual - 1\n",
      "292: pred - 2, actual - 2\n",
      "293: pred - 2, actual - 2\n",
      "294: pred - 2, actual - 1\n",
      "295: pred - 2, actual - 1\n",
      "296: pred - 1, actual - 2\n",
      "297: pred - 1, actual - 2\n",
      "298: pred - 2, actual - 2\n",
      "299: pred - 2, actual - 2\n",
      "300: pred - 1, actual - 1\n",
      "301: pred - 2, actual - 1\n",
      "302: pred - 2, actual - 2\n",
      "303: pred - 2, actual - 1\n",
      "304: pred - 2, actual - 1\n",
      "305: pred - 1, actual - 1\n",
      "306: pred - 2, actual - 1\n",
      "307: pred - 2, actual - 1\n",
      "308: pred - 1, actual - 1\n",
      "309: pred - 1, actual - 1\n",
      "310: pred - 2, actual - 1\n",
      "311: pred - 2, actual - 2\n",
      "312: pred - 2, actual - 2\n",
      "313: pred - 2, actual - 2\n",
      "314: pred - 1, actual - 2\n",
      "315: pred - 2, actual - 2\n",
      "316: pred - 2, actual - 1\n",
      "317: pred - 2, actual - 2\n",
      "318: pred - 1, actual - 1\n",
      "319: pred - 1, actual - 1\n",
      "320: pred - 1, actual - 1\n",
      "321: pred - 2, actual - 2\n",
      "322: pred - 1, actual - 1\n",
      "323: pred - 1, actual - 2\n",
      "324: pred - 2, actual - 2\n",
      "325: pred - 2, actual - 2\n",
      "326: pred - 2, actual - 2\n",
      "327: pred - 2, actual - 2\n",
      "328: pred - 2, actual - 1\n",
      "329: pred - 1, actual - 1\n",
      "330: pred - 1, actual - 1\n",
      "331: pred - 2, actual - 2\n",
      "332: pred - 1, actual - 1\n",
      "333: pred - 1, actual - 1\n",
      "334: pred - 2, actual - 2\n",
      "335: pred - 1, actual - 2\n",
      "336: pred - 2, actual - 1\n",
      "337: pred - 1, actual - 1\n",
      "338: pred - 1, actual - 2\n",
      "339: pred - 1, actual - 1\n",
      "340: pred - 2, actual - 2\n",
      "341: pred - 2, actual - 2\n",
      "342: pred - 2, actual - 1\n",
      "343: pred - 2, actual - 1\n",
      "344: pred - 2, actual - 2\n",
      "345: pred - 2, actual - 2\n",
      "done. \n"
     ]
    }
   ],
   "source": [
    "# leave-one-out classification\n",
    "\n",
    "predLabel = []\n",
    "trueLabel = []\n",
    "currSbj = 1;\n",
    "\n",
    "for sbj in subjectId:\n",
    "    # sbj is being tested, others are used to train the classifier\n",
    "    trainSbj = list(subjectId)\n",
    "    trainSbj.remove(sbj)\n",
    "    # create the dictionary\n",
    "    trainDict = make_dictionary(trainSbj, 5)\n",
    "    trainText = []\n",
    "    # create the training set\n",
    "    for tSbj in trainSbj:\n",
    "        tmpText = ''\n",
    "        for line in codecs.open(os.path.join(path, intvIdx, tSbj + '.txt'), 'r' , 'utf-8'):\n",
    "            tmpText = tmpText + ' ' + line\n",
    "        trainText.append([extract_feature(tmpText, trainDict), category[tSbj]])\n",
    "    # train classifier\n",
    "    classifier = nltk.NaiveBayesClassifier.train(trainText)\n",
    "\n",
    "    # now the test set\n",
    "    trueLabel.append( category[sbj] )\n",
    "    testText = ''\n",
    "    for line in codecs.open(os.path.join(path, intvIdx, sbj + '.txt'), 'r' , 'utf-8'):\n",
    "        testText = testText + ' ' + line\n",
    "    # predict!\n",
    "    currPred = classifier.classify(extract_feature(testText, trainDict))\n",
    "    predLabel.append( currPred )\n",
    "    \n",
    "    print(str(currSbj) + ': pred - ' + str(currPred) + ', actual - ' + str(category[sbj]) )\n",
    "    currSbj = currSbj + 1\n",
    "\n",
    "print('done. ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.72      0.55      0.62       148\n",
      "          2       0.71      0.84      0.77       197\n",
      "\n",
      "avg / total       0.72      0.72      0.71       345\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ok, it is POSSIBLE TO PREDICT cohort from the writings.\n",
    "\n",
    "print(metrics.classification_report(trueLabel, predLabel))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                  values = True                1 : 2      =     12.8 : 1.0\n",
      "              everything = True                1 : 2      =     12.8 : 1.0\n",
      "                   never = True                1 : 2      =      5.9 : 1.0\n",
      "                    into = True                1 : 2      =      5.8 : 1.0\n",
      "                     old = True                1 : 2      =      5.8 : 1.0\n",
      "                     now = True                1 : 2      =      5.6 : 1.0\n",
      "                     see = True                1 : 2      =      5.6 : 1.0\n",
      "                    dont = True                1 : 2      =      5.1 : 1.0\n",
      "                    such = True                1 : 2      =      4.9 : 1.0\n",
      "                    same = True                1 : 2      =      4.9 : 1.0\n",
      "                 writing = True                1 : 2      =      4.9 : 1.0\n",
      "                 trouble = True                1 : 2      =      4.9 : 1.0\n",
      "                     rap = True                1 : 2      =      4.9 : 1.0\n",
      "                   angry = True                1 : 2      =      4.9 : 1.0\n",
      "                    stay = True                1 : 2      =      4.9 : 1.0\n",
      "                    many = True                1 : 2      =      4.9 : 1.0\n",
      "                  happen = True                1 : 2      =      4.5 : 1.0\n",
      "               different = True                1 : 2      =      4.0 : 1.0\n",
      "                   those = True                1 : 2      =      4.0 : 1.0\n",
      "                   whole = True                1 : 2      =      4.0 : 1.0\n",
      "                 feeling = True                1 : 2      =      3.5 : 1.0\n",
      "                  others = True                1 : 2      =      3.5 : 1.0\n",
      "                   grade = True                2 : 1      =      3.3 : 1.0\n",
      "                   cause = True                1 : 2      =      3.2 : 1.0\n",
      "                    were = True                1 : 2      =      3.2 : 1.0\n",
      "                    take = True                1 : 2      =      3.1 : 1.0\n",
      "                  myself = True                1 : 2      =      3.0 : 1.0\n",
      "                     lot = True                1 : 2      =      3.0 : 1.0\n",
      "               religious = True                1 : 2      =      2.9 : 1.0\n",
      "                   smile = True                1 : 2      =      2.9 : 1.0\n",
      "                    than = True                1 : 2      =      2.9 : 1.0\n",
      "                   comes = True                1 : 2      =      2.9 : 1.0\n",
      "                   calms = True                1 : 2      =      2.9 : 1.0\n",
      "                   trust = True                1 : 2      =      2.9 : 1.0\n",
      "                   alone = True                1 : 2      =      2.9 : 1.0\n",
      "                everyday = True                1 : 2      =      2.9 : 1.0\n",
      "                 another = True                1 : 2      =      2.8 : 1.0\n",
      "               inportant = True                1 : 2      =      2.8 : 1.0\n",
      "                     has = True                1 : 2      =      2.8 : 1.0\n",
      "                    help = True                1 : 2      =      2.8 : 1.0\n",
      "                    even = True                1 : 2      =      2.8 : 1.0\n",
      "                anything = True                1 : 2      =      2.8 : 1.0\n",
      "                 without = True                1 : 2      =      2.8 : 1.0\n",
      "                    side = True                2 : 1      =      2.8 : 1.0\n",
      "                    part = True                2 : 1      =      2.8 : 1.0\n",
      "               sometimes = True                1 : 2      =      2.7 : 1.0\n",
      "                     but = True                1 : 2      =      2.6 : 1.0\n",
      "                  friend = True                1 : 2      =      2.6 : 1.0\n",
      "                    talk = True                1 : 2      =      2.5 : 1.0\n",
      "                     say = True                1 : 2      =      2.5 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# now, show me the informative features\n",
    "\n",
    "dictionary = make_dictionary(subjectId, 5)\n",
    "\n",
    "allText = []\n",
    "\n",
    "for sbj in subjectId:\n",
    "    tmpText = ''\n",
    "    for line in codecs.open(os.path.join(path, intvIdx, sbj + '.txt'), 'r' , 'utf-8'):\n",
    "        tmpText = tmpText + ' ' + line\n",
    "        allText.append([extract_feature(tmpText, dictionary), category[sbj]])\n",
    "\n",
    "# train classifier based on all information\n",
    "classifier = nltk.NaiveBayesClassifier.train(allText)\n",
    "\n",
    "# and show me the informative features\n",
    "classifier.show_most_informative_features(50)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
